{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Passing pipelines to mitigation techniques\n==========================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook shows how to pass sklearn.pipeline.Pipeline to mitigation\ntechniques from Fairlearn. Note that the notebook is not to be used as\nan example for how to assess and mitigate fairness. It is merely a\ndemonstration of the technical aspects of passing\nsklearn.pipeline.Pipeline. For more information around proper fairness\nassessment and mitigation please refer to the user\\_guide.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import json\nfrom fairlearn.datasets import fetch_adult\nfrom fairlearn.postprocessing import ThresholdOptimizer, plot_threshold_optimizer\nfrom fairlearn.reductions import ExponentiatedGradient, DemographicParity\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.compose import make_column_selector as selector\nfrom sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we load the \"Adult\" census dataset and split its features,\nsensitive features, and labels into train and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = fetch_adult(as_frame=True)\nX_raw = data.data\ny = (data.target == \">50K\") * 1\nA = X_raw[\"sex\"]\n\n(X_train, X_test, y_train, y_test, A_train, A_test) = train_test_split(\n    X_raw, y, A, test_size=0.3, random_state=12345, stratify=y)\n\nX_train = X_train.reset_index(drop=True)\nX_test = X_test.reset_index(drop=True)\ny_train = y_train.reset_index(drop=True)\ny_test = y_test.reset_index(drop=True)\nA_train = A_train.reset_index(drop=True)\nA_test = A_test.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To illustrate Fairlearn's compatibility with \\~sklearn.pipeline.Pipeline\nwe first need to build our pipeline. In the following we assemble a\npipeline by combining preprocessing steps with an estimator. The\npreprocessing steps include imputing, scaling for numerical features and\none-hot encoding for categorical features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "numeric_transformer = Pipeline(\n    steps=[\n        (\"impute\", SimpleImputer()),\n        (\"scaler\", StandardScaler()),\n    ]\n)\ncategorical_transformer = Pipeline(\n    [\n        (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")),\n    ]\n)\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\", numeric_transformer, selector(dtype_exclude=\"category\")),\n        (\"cat\", categorical_transformer, selector(dtype_include=\"category\")),\n    ]\n)\n\npipeline = Pipeline(\n    steps=[\n        (\"preprocessor\", preprocessor),\n        (\n            \"classifier\",\n            LogisticRegression(solver=\"liblinear\", fit_intercept=True),\n        ),\n    ]\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we will pass the pipeline to some of our mitigation techniques,\nstarting with fairlearn.postprocessing.ThresholdOptimizer:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "threshold_optimizer = ThresholdOptimizer(\n    estimator=pipeline,\n    constraints=\"demographic_parity\",\n    predict_method=\"predict_proba\",\n    prefit=False)\nthreshold_optimizer.fit(X_train, y_train, sensitive_features=A_train)\nprint(threshold_optimizer.predict(X_test, sensitive_features=A_test))\nprint(json.dumps(\n    threshold_optimizer.interpolated_thresholder_.interpolation_dict,\n    default=str,\n    indent=4))\nplot_threshold_optimizer(threshold_optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similarly, fairlearn.reductions.ExponentiatedGradient works with\npipelines. Since it requires the `sample_weight`{.sourceCode} parameter\nof the underlying estimator internally we need to provide it with the\ncorrect way of passing `sample_weight`{.sourceCode} to just the\n`\"classifier\"`{.sourceCode} step using the step name followed by two\nunderscores and `sample_weight`{.sourceCode}.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "exponentiated_gradient = ExponentiatedGradient(\n    estimator=pipeline,\n    constraints=DemographicParity(),\n    sample_weight_name=\"classifier__sample_weight\")\nexponentiated_gradient.fit(X_train, y_train, sensitive_features=A_train)\nprint(exponentiated_gradient.predict(X_test))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}