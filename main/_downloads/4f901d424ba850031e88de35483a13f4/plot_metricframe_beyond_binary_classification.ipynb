{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MetricFrame: Beyond Binary Classification\n=========================================\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook contains examples of using \\~fairlearn.metrics.MetricFrame\nfor tasks which go beyond simple binary classification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics as skm\nimport functools\nfrom fairlearn.metrics import MetricFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Multiclass & Nonscalar Results\n==============================\n\nSuppose we have a multiclass problem, with labels $\\in {0, 1, 2}$, and\nthat we wish to generate confusion matrices for each subgroup identified\nby the sensitive feature $\\in { a, b, c, d}$. This is supported readily\nby \\~fairlearn.metrics.MetricFrame, which does not require the result of\na metric to be a scalar.\n\nFirst, let us generate some random input data:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nrng = np.random.default_rng(seed=96132)\n\nn_rows = 1000\nn_classes = 3\nn_sensitive_features = 4\n\ny_true = rng.integers(n_classes, size=n_rows)\ny_pred = rng.integers(n_classes, size=n_rows)\n\ntemp = rng.integers(n_sensitive_features, size=n_rows)\ns_f = [chr(ord('a')+x) for x in temp]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To use \\~sklearn.metrics.confusion\\_matrix, we need to prebind the\nlabels argument, since it is possible that some of the subgroups will\nnot contain all of the possible labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "conf_mat = functools.partial(skm.confusion_matrix,\n                             labels=np.unique(y_true))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With this now available, we can create our\n\\~fairlearn.metrics.MetricFrame:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mf = MetricFrame(metrics={'conf_mat': conf_mat},\n                 y_true=y_true,\n                 y_pred=y_pred,\n                 sensitive_features=s_f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this, we can view the overall confusion matrix:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mf.overall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And also the confusion matrices for each subgroup:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mf.by_group"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obviously, the other methods such as\n\\~fairlearn.metrics.MetricFrame.group\\_min will not work, since\noperations such as 'less than' are not well defined for matrices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Metric functions with different return types can also be mixed in a\nsingle \\~fairlearn.metrics.MetricFrame. For example:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "recall = functools.partial(skm.recall_score, average='macro')\n\nmf2 = MetricFrame(metrics={'conf_mat': conf_mat,\n                           'recall': recall\n                           },\n                  y_true=y_true,\n                  y_pred=y_pred,\n                  sensitive_features=s_f)\n\nprint(\"Overall values\")\nprint(mf2.overall)\nprint(\"Values by group\")\nprint(mf2.by_group)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Non-scalar Inputs\n=================\n\n\\~fairlearn.metrics.MetricFrame does not require its inputs to be\nscalars either. To demonstrate this, we will use an image recognition\nexample (kindly supplied by Ferdane Bekmezci, Hamid Vaezi Joze and\nSamira Pouyanfar).\n\nImage recognition algorithms frequently construct a bounding box around\nregions where they have found their target features. For example, if an\nalgorithm detects a face in an image, it will place a bounding box\naround it. These bounding boxes constitute y\\_pred for\n\\~fairlearn.metrics.MetricFrame. The y\\_true values then come from\nbounding boxes marked by human labellers.\n\nBounding boxes are often compared using the 'iou' metric. This computes\nthe intersection and the union of the two bounding boxes, and returns\nthe ratio of their areas. If the bounding boxes are identical, then the\nmetric will be 1; if disjoint then it will be 0. A function to do this\nis:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def bounding_box_iou(box_A_input, box_B_input):\n    # The inputs are array-likes in the form\n    # [x_0, y_0, delta_x,delta_y]\n    # where the deltas are positive\n\n    box_A = np.array(box_A_input)\n    box_B = np.array(box_B_input)\n\n    if box_A[2] < 0:\n        raise ValueError(\"Bad delta_x for box_A\")\n    if box_A[3] < 0:\n        raise ValueError(\"Bad delta y for box_A\")\n    if box_B[2] < 0:\n        raise ValueError(\"Bad delta x for box_B\")\n    if box_B[3] < 0:\n        raise ValueError(\"Bad delta y for box_B\")\n\n    # Convert deltas to co-ordinates\n    box_A[2:4] = box_A[0:2] + box_A[2:4]\n    box_B[2:4] = box_B[0:2] + box_B[2:4]\n\n    # Determine the (x, y)-coordinates of the intersection rectangle\n    x_A = max(box_A[0], box_B[0])\n    y_A = max(box_A[1], box_B[1])\n    x_B = min(box_A[2], box_B[2])\n    y_B = min(box_A[3], box_B[3])\n\n    if (x_B < x_A) or (y_B < y_A):\n        return 0\n\n    # Compute the area of intersection rectangle\n    interArea = (x_B - x_A) * (y_B - y_A)\n\n    # Compute the area of both the prediction and ground-truth\n    # rectangles\n    box_A_area = (box_A[2] - box_A[0]) * (box_A[3] - box_A[1])\n    box_B_area = (box_B[2] - box_B[0]) * (box_B[3] - box_B[1])\n\n    # Compute the intersection over union by taking the intersection\n    # area and dividing it by the sum of prediction + ground-truth\n    # areas - the intersection area\n    iou = interArea / float(box_A_area + box_B_area - interArea)\n\n    return iou"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is a metric for two bounding boxes, but for\n\\~fairlearn.metrics.MetricFrame we need to compare two lists of bounding\nboxes. For the sake of simplicity, we will return the mean value of\n'iou' for the two lists, but this is by no means the only choice:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def mean_iou(true_boxes, predicted_boxes):\n    if len(true_boxes) != len(predicted_boxes):\n        raise ValueError(\"Array size mismatch\")\n\n    all_iou = [\n        bounding_box_iou(y_true, y_pred)\n        for y_true, y_pred in zip(true_boxes, predicted_boxes)\n    ]\n\n    return np.mean(all_iou)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We need to generate some input data, so first create a function to\ngenerate a single random bounding box:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def generate_bounding_box(max_coord, max_delta, rng):\n    corner = max_coord * rng.random(size=2)\n    delta = max_delta * rng.random(size=2)\n\n    return np.concatenate((corner, delta))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now use this to create sample y\\_true and y\\_pred arrays of bounding\nboxes:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def many_bounding_boxes(n_rows, max_coord, max_delta, rng):\n    return [\n        generate_bounding_box(max_coord, max_delta, rng)\n        for _ in range(n_rows)\n    ]\n\n\ntrue_bounding_boxes = many_bounding_boxes(n_rows, 5, 10, rng)\npred_bounding_boxes = many_bounding_boxes(n_rows, 5, 10, rng)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can use these in a \\~fairlearn.metrics.MetricFrame:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mf_bb = MetricFrame(metrics={'mean_iou': mean_iou},\n                    y_true=true_bounding_boxes,\n                    y_pred=pred_bounding_boxes,\n                    sensitive_features=s_f)\n\nprint(\"Overall metric\")\nprint(mf_bb.overall)\nprint(\"Metrics by group\")\nprint(mf_bb.by_group)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The individual entries in the y\\_true and y\\_pred arrays can be\narbitrarily complex. It is the metric functions which give meaning to\nthem. Similarly, \\~fairlearn.metrics.MetricFrame does not impose\nrestrictions on the return type. One can envisage an image recognition\ntask where there are multiple detectable objects in each picture, and\nthe image recognition algorithm produces multiple bounding boxes (not\nnecessarily in a 1-to-1 mapping either). The output of such a scenario\nmight well be a matrix of some description. Another case where both the\ninput data and the metrics will be complex is natural language\nprocessing, where each row of the input could be an entire sentence,\npossibly with complex word embeddings included.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conclusion\n==========\n\nThis notebook has given some taste of the flexibility of\n\\~fairlearn.metrics.MetricFrame when it comes to inputs, outputs and\nmetric functions. The input arrays can have elements of arbitrary types,\nand the return values from the metric functions can also be of any type\n(although methods such as \\~fairlearn.metrics.MetricFrame.group\\_min may\nnot work).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}